"""Convert the pickles generated by parallel_rollout_main.py to tf records."""
import os
import pickle
import tempfile

from absl import app
from absl import flags
import ray
import tensorflow as tf

from rl755.common import structs
from rl755.common.misc import divide_chunks

# TODO(mmatena): Compute this based on desired shard size. For 2000 cartpole rounds
#                it seems like 8 is a good number. We want shards to be around 100-200 MB.
flags.DEFINE_integer('pickles_per_tfrecord_file', None,
                     'Number of pickled files to put in each tfrecord file.',
                     lower_bound=1)
flags.DEFINE_string('out_dir', None, 'The directory to write the tfrecords to.')

flags.mark_flag_as_required('pickles_per_tfrecord_file')
flags.mark_flag_as_required('out_dir')


@ray.remote
def convert_to_tf_records(filepaths, out_dir, pickles_per_tfrecord_file):
  for files in divide_chunks(filepaths, pickles_per_tfrecord_file):
    raise ValueError("Add a UUID to the suffix so that we don't mess with existing tfrecord files when renaming.")
    fd, record_file = tempfile.mkstemp(dir=out_dir, suffix=".tfrecord")
    with tf.io.TFRecordWriter(record_file) as writer:
      for file in files:
        rollout = pickle.load(open(file, "rb"))
        record = structs.to_tf_record(rollout)
        writer.write(record.SerializeToString())
    os.close(fd)


def main(_):
  pass


if __name__ == '__main__':
  app.run(main)
